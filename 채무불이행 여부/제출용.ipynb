{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = os.getcwd()\n",
    "train_path = os.path.join(file_path, \"데이터셋\", \"train.csv\")\n",
    "test_path = os.path.join(file_path, \"데이터셋\", \"test.csv\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"font\", family = \"NanumGothic\")\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.countplot(x = \"대출 상환 기간\", hue = \"채무 불이행 여부\", data = train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    def year(x):\n",
    "        return \"\".join(v.replace(\"이상\", \"\").replace(\"년\", \"\") for v in x.split(\" \"))\n",
    "\n",
    "    def year1(x):\n",
    "        return \"\".join(v.replace('1미만', \"0\") for v in x.split(\" \"))\n",
    "    \n",
    "    df[\"신용 거래 연수\"] = df[\"신용 거래 연수\"].astype(float)\n",
    "    \n",
    "    \n",
    "    cols = ([\"주거 형태\", \"대출 목적\", \"대출 상환 기간\"])\n",
    "    for c in cols:\n",
    "        lb = LabelEncoder()\n",
    "        lb.fit(df[c].values)\n",
    "        df[c] = lb.transform(list(df[c].values))\n",
    "        df[c] = df[c].astype(int)\n",
    "\n",
    "    \n",
    "\n",
    " \n",
    "    df[\"현재 직장 근속 연수\"] = df[\"현재 직장 근속 연수\"].apply(year)\n",
    "    df[\"현재 직장 근속 연수\"] = df[\"현재 직장 근속 연수\"].apply(year1).astype(int)\n",
    "    df[\"현재 대출 잔액\"] = df[\"현재 대출 잔액\"].where((df[\"현재 대출 잔액\"] > 0), np.nan)\n",
    "    df[\"현재 대출 잔액\"] = df[\"현재 대출 잔액\"].fillna(df[\"현재 대출 잔액\"].median())\n",
    "    df[\"최대 신용한도\"] = df[\"최대 신용한도\"].where((df[\"최대 신용한도\"] > 0), np.nan)\n",
    "    df[\"최대 신용한도\"] = df[\"최대 신용한도\"].fillna(df[\"최대 신용한도\"].median())\n",
    "    df[\"대출액+신용액\"] = df[\"현재 대출 잔액\"] + df[\"현재 미상환 신용액\"]\n",
    "    df[\"상환액 분위\"] = pd.qcut(df[\"대출액+신용액\"], 5, labels = [1,2,3,4,5], duplicates = \"drop\").astype(int)\n",
    "\n",
    "    df[\"신용거래분위\"] = pd.qcut(df[\"신용 거래 연수\"], 5, labels = [1,2,3,4,5], duplicates = \"drop\").astype(int)\n",
    "    df[\"신용점수분위\"] = pd.qcut(df[\"신용 점수\"], 5, labels = [1,2,3,4,5], duplicates= \"drop\").astype(int)\n",
    "\n",
    "    df[\"연간소득분위\"] = pd.qcut(df[\"연간 소득\"], 5, labels = [1,2,3,4,5], duplicates = \"drop\").astype(int)\n",
    "    df[\"개설된_신용계좌_분위수\"] = pd.qcut(df[\"개설된 신용계좌 수\"], 5, labels = [1,2,3,4,5], duplicates = \"drop\").astype(int)\n",
    "    df[\"대출잔액 분위수\"] = pd.qcut(df[\"현재 대출 잔액\"], 5, labels = [1,2,3,4,5], duplicates= \"drop\").astype(int)\n",
    "    df[\"직장근속연수 분위수\"] = pd.qcut(df[\"현재 직장 근속 연수\"], 7, labels = [1,2,3,4,5], duplicates= \"drop\").astype(int)\n",
    "    df[\"연체 이후 경과 개월 분위수\"] = pd.qcut(df[\"마지막 연체 이후 경과 개월 수\"], 5, labels = [1,2,3,4,5], duplicates = \"drop\").astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    df[\"신용한도vs대출잔액\"] = (df[\"현재 대출 잔액\"] + df[\"현재 미상환 신용액\"] )  / ((df[\"최대 신용한도\"] * df[\"개설된 신용계좌 수\"]))* 100\n",
    "\n",
    "\n",
    "    df[\"DTI\"] = ((df[\"현재 대출 잔액\"] + df[\"현재 미상환 신용액\"]) / df[\"연간 소득\"]) * 100\n",
    "    df[\"DSR\"] = (((df[\"월 상환 부채액\"] + 1)) / (df[\"연간 소득\"]/ 12)) * 100\n",
    "\n",
    "    df[\"DTI분위\"] = pd.qcut(df[\"DTI\"], 5, labels = [1,2,3,4,5], duplicates= \"drop\").astype(int)\n",
    "    df[\"DSR분위\"] = pd.qcut(df[\"DSR\"], 5, labels = [1,2,3,4,5], duplicates= \"drop\").astype(int)\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "    df[\"신용위험\"] = ((df[\"개설된_신용계좌_분위수\"] >= 3) & (df[\"신용점수분위\"] <= 3) & (df[\"신용거래분위\"] <= 3)).astype(int)\n",
    "    df[\"소득위험\"] = ((df[\"직장근속연수 분위수\"] < 3) & (df[\"연간소득분위\"] < 3)).astype(int)\n",
    "    df[\"대출위험\"] = ((df[\"상환액 분위\"] > 3) & (df[\"DSR분위\"] < 3)).astype(int)\n",
    "    df[\"파산위험\"] = ((df[\"신용 문제 발생 횟수\"] > 0) | ((df[\"개인 파산 횟수\"] > 0) | (df[\"체납 세금 압류 횟수\"] > 0))).astype(int)\n",
    "    df[\"부채통합위험\"] = ((df[\"대출 목적\"] == 4) & (df[\"DTI분위\"] > 3)).astype(int)\n",
    "    df[\"부채통합위험2\"] = ((df[\"대출 목적\"] != 4) & (df[\"파산위험\"] == 1)).astype(int)\n",
    "    df[\"장기상환위험\"] = ((df[\"대출 상환 기간\"] == 1) & (df[\"신용점수분위\"] < 3)).astype(int)\n",
    "    \n",
    "    \n",
    "\n",
    "    df[\"위험분자\"] = df[\"신용위험\"] + df[\"소득위험\"] + df[\"대출위험\"] + df[\"파산위험\"] + df[\"부채통합위험\"] +df[\"부채통합위험2\"] + df[\"장기상환위험\"]\n",
    "\n",
    "\n",
    "\n",
    "    df[\"근속연수vs거래연수\"] = (df[\"현재 직장 근속 연수\"] / df[\"신용 거래 연수\"]) * 100\n",
    "\n",
    "    df[\"개설계좌vs연체이후개월수\"] = df[\"개설된 신용계좌 수\"] / (df[\"마지막 연체 이후 경과 개월 수\"] + 1) * 100\n",
    "\n",
    "\n",
    "\n",
    "    df = df.drop([\"대출액+신용액\", \"DSR분위\", \"DTI분위\", \"상환액 분위\"], axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = preprocess(train_df)\n",
    "test = preprocess(test_df)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "cols = [\"연간 소득\", \"월 상환 부채액\", \"현재 대출 잔액\", \"현재 미상환 신용액\", \"신용 점수\", \"DTI\", \"DSR\", \"개설된 신용계좌 수\", \"신용 거래 연수\", \"신용한도vs대출잔액\", \"최대 신용한도\", \"근속연수vs거래연수\", \"개설계좌vs연체이후개월수\"]\n",
    "for c in cols:\n",
    "    train[c] = train[c].where((train[c] > 0), np.nan)\n",
    "    test[c] = test[c].where((test[c] > 0), np.nan)\n",
    "    train[c] = train[c].fillna(train[c].median())\n",
    "    test[c] = test[c].fillna(test[c].median())\n",
    "    \n",
    "    train[c], l = boxcox(train[c])\n",
    "    test[c]= boxcox(test[c], lmbda = l)\n",
    "print(train[cols].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[cols].hist(figsize = (12,8), bins = 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train[\"채무 불이행 여부\"]\n",
    "uid = test[\"UID\"]\n",
    "\n",
    "train = train.drop([\"채무 불이행 여부\", \"UID\"], axis = 1)\n",
    "test = test.drop(\"UID\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist(figsize = (12,8),bins = 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()\n",
    "corr_cols = corrmat.index[abs(corrmat[\"위험분자\"] >= 0.1)]\n",
    "plt.figure(figsize = (30,15))\n",
    "sns.heatmap(train.corr(), annot = True, cmap = \"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()\n",
    "X_scaled = minmax.fit_transform(train)\n",
    "test_scaled = minmax.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state= 42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history = []\n",
    "kf = KFold(n_splits = 2, shuffle= True, random_state= 42)\n",
    "fold = 1\n",
    "roc_auc_scores = []\n",
    "\n",
    "for train_index, valid_index in kf.split(X_resampled):\n",
    "    print(f\"Fold {fold} 시작!\")\n",
    "    \n",
    "    X_train_fold, X_valid_fold = X_resampled[train_index], X_resampled[valid_index]\n",
    "    y_train_fold, y_valid_fold = y_resampled[train_index], y_resampled[valid_index]\n",
    "\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation = \"relu\", input_shape = (X_train_fold.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.30),\n",
    "        tf.keras.layers.Dense(64, activation = \"relu\"),\n",
    "        tf.keras.layers.Dropout(0.30),\n",
    "        tf.keras.layers.Dense(32, activation = \"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation= \"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate= 1e-5),\n",
    "        loss = \"binary_crossentropy\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = \"val_loss\",\n",
    "        patience = 5,\n",
    "        min_delta = 0.001,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        validation_data = (X_valid_fold, y_valid_fold),\n",
    "        epochs = 100,\n",
    "        callbacks = earlystop,\n",
    "        batch_size = 32,\n",
    "        verbose = 1\n",
    "    )\n",
    "    all_history.append(history.history)\n",
    "    y_valid_pred = model.predict(X_valid_fold).ravel()\n",
    "    roc_auc = roc_auc_score(y_valid_fold, y_valid_pred)\n",
    "    print(f\"Fold{fold} ROC-AUC score {roc_auc:.4f}\")\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    fold += 1\n",
    "\n",
    "print(f\"교차 검증 ROC-AUC 평균점수 {np.mean(roc_auc_scores):.4f}\")\n",
    "\n",
    "for i, history in enumerate(all_history):\n",
    "    epochs = range(1, len(history[\"loss\"]) + 1)\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, history[\"accuracy\"], label = \"Train Accuracy\")\n",
    "    plt.plot(epochs, history[\"val_accuracy\"], label = \"Validation Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, history[\"loss\"], label = \"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label = \"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_scaled).ravel()\n",
    "\n",
    "sub_path = os.path.join(file_path, \"데이터셋\", \"sample_submission.csv\")\n",
    "submission = pd.read_csv(sub_path)\n",
    "\n",
    "submission[\"채무 불이행 확률\"] = pred * 100\n",
    "submission.to_csv(\"C:/Users/yunju/OneDrive/바탕 화면/submissions/채무불이행 예측/submission(제출용).csv\", index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
